{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a1d8f0-6493-4316-9086-5d8d48abf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "\n",
    "import numpy as np\n",
    "import numpy.matlib\n",
    "import pandas as pd\n",
    "import pyedflib\n",
    "from scipy.signal import find_peaks_cwt, welch\n",
    "from scipy.signal import decimate\n",
    "from datetime import timedelta\n",
    "from mne.filter import filter_data\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a93935-18b4-4327-a14e-4d3f20e97c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\bobby\\Documents\\Github\\WatchPD\\Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a79c65-4dec-4df5-8e1b-27ad3c6b3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_lists(subject):\n",
    "    '''\n",
    "    Creates a list of files for each sensor (Left/right/chest) located in the indicated patients\n",
    "    sensor file folder.\n",
    "    \n",
    "    '''\n",
    "    subj_folder = os.path.join(path,'data',subject)\n",
    "\n",
    "    # sensor names\n",
    "    left_sensors = ['13797', '13799', '13794', '13806']\n",
    "    right_sensors = ['13805', '13801', '13793', '13795']\n",
    "    chest_sensors = ['13804', '13792', '13803', '13796']\n",
    "\n",
    "    edf_files = [f for f in listdir(subj_folder) if (isfile(join(subj_folder, f))) and (f[0] != '_' and f[-3:] == 'edf')]\n",
    "\n",
    "    left_files = []\n",
    "    right_files = []\n",
    "    chest_files = []\n",
    "\n",
    "    for f in edf_files:\n",
    "        if f[0:5] in left_sensors:\n",
    "            left_files.append(join(subj_folder, f))\n",
    "        elif f[0:5] in right_sensors:\n",
    "            right_files.append(join(subj_folder, f))\n",
    "        elif f[0:5] in chest_sensors:\n",
    "            chest_files.append(join(subj_folder, f))\n",
    "\n",
    "    left_files = sorted(left_files)\n",
    "    right_files = sorted(right_files)\n",
    "    chest_files = sorted(chest_files)\n",
    "\n",
    "    return left_files, right_files, chest_files\n",
    "\n",
    "\n",
    "def extract_raw_trials(left_files, right_files, chest_files, esm_frame,\n",
    "                       esm_window_length=15, feature_window_length=60):\n",
    "    '''\n",
    "    Reads the sensor files and aligns the data with the esm data. Then\n",
    "    data quality is checked.\n",
    "    Returns cleaned and synced trial data and ESM beeps\n",
    "    '''\n",
    "\n",
    "    files = [left_files, right_files, chest_files]\n",
    "\n",
    "    n_beeps = esm_frame.shape[0]\n",
    "    n_sensors = len(files)\n",
    "    trials = [[[]] * n_beeps] * n_sensors\n",
    "    trials = np.zeros((n_sensors,n_beeps,int(esm_window_length * WINDOW_LENGTH * 100),6))\n",
    "\n",
    "    found_trials = np.zeros((n_beeps, n_sensors))\n",
    "    for i, f in enumerate(files):\n",
    "        for file in f:\n",
    "            print(file)\n",
    "\n",
    "            # Read the data from the filepath, raise error if file is not in the correct format\n",
    "            try:\n",
    "                labels, timestamps, data, fs = read_edf_data(file)  # as input instead: leftFiles\n",
    "                if data.shape[1] < fs * feature_window_length:\n",
    "                    raise ValueError('File too short to proceed.')\n",
    "            except Exception:\n",
    "                print('%s is broken' % file)\n",
    "                continue\n",
    "\n",
    "            data = pd.DataFrame(data.T, index=timestamps)\n",
    "            print(data.shape)\n",
    "            for beep in range(n_beeps):\n",
    "                if found_trials[beep, i] == 1:\n",
    "                    continue\n",
    "\n",
    "                # Get the corresponding time\n",
    "                beep_time = pd.to_datetime(esm_frame['beep_time_start'].iloc[beep])\n",
    "                timediff = np.min(np.abs(data.index - beep_time))\n",
    "                # Find corresponding moment for beep time in the sensor data by\n",
    "                # calculating the difference in sensor and beep timestamps and\n",
    "                # select the index with the smallest difference.\n",
    "                if timediff > timedelta(minutes=esm_window_length):\n",
    "                    # If the time difference is larger than the window length,\n",
    "                    # remove beep\n",
    "                    continue\n",
    "                pos = np.argmin(np.abs(data.index - beep_time))\n",
    "                # For the smallest time difference, find the position in the sensor data\n",
    "                if pos > esm_window_length * WINDOW_LENGTH * fs:\n",
    "                    trials[i,beep,:,:] = data.iloc[pos - (int(esm_window_length * WINDOW_LENGTH * fs)):pos].values\n",
    "                    found_trials[beep, i] = 1\n",
    "    \n",
    "    keep = np.sum(found_trials, axis=1) == n_sensors  # Keep trials if all three sensors contain values\n",
    "    trialData = np.zeros((np.sum(keep), int(esm_window_length * WINDOW_LENGTH * fs), 3 * 6))\n",
    "    counter = 0\n",
    "    for beep in range(n_beeps):\n",
    "        if keep[beep]:\n",
    "            temp = np.concatenate((trials[0,beep,:,:], trials[1,beep,:,:], trials[2,beep,:,:]), axis=1)\n",
    "            trialData[counter, :, :] = temp\n",
    "            counter += 1\n",
    "    foundESM = esm_frame.iloc[keep, :]\n",
    "\n",
    "    return trialData, foundESM, data\n",
    "\n",
    "\n",
    "def read_edf_data(filename):\n",
    "    '''\n",
    "    Reads and .edf file and returns labels, timestamps, signal buffers and samplefrequency.\n",
    "    '''\n",
    "\n",
    "    # Extract data\n",
    "    f = pyedflib.EdfReader(filename)\n",
    "    fs = f.getSampleFrequencies()[0]\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sig_bufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\n",
    "    for i in np.arange(n):\n",
    "        sig_bufs[i, :] = f.readSignal(i)\n",
    "\n",
    "    # Get starting time\n",
    "    starting_time = filename[-19:-4]\n",
    "    starting_time = pd.to_datetime(starting_time, format='%Y%m%d_%H%M%S', errors='ignore')\n",
    "\n",
    "    sig_bufs = decimate(sig_bufs, DOWNSAMPLING, axis=1)\n",
    "    fs = fs / DOWNSAMPLING\n",
    "    freq = '%d ms' % (1000 / fs)\n",
    "    timestamps = pd.date_range(start=starting_time, periods=sig_bufs.shape[1], freq=freq)\n",
    "\n",
    "    return signal_labels, timestamps, sig_bufs, fs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb5066f-6e9d-4cf3-8ff0-9e55934dc3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_LENGTH = 60\n",
    "DOWNSAMPLING = 2\n",
    "FEATURE_WINDOW_LENGTH = 60\n",
    "ESM_WINDOW_LENGTH = 15\n",
    "\n",
    "    # define patient to use\n",
    "all_subjs = ['110001']\n",
    "esm = pd.read_csv(os.path.join(path,'data','EMA_data.csv'), )\n",
    "for subject in all_subjs:\n",
    "        leftFiles, rightFiles, chestFiles = get_file_lists(subject)\n",
    "        t = time.time()\n",
    "        trial_data, selected_esm, data = extract_raw_trials(leftFiles, rightFiles, chestFiles, esm[esm['ID'] == int(subject)])\n",
    "        print(time.time() - t)\n",
    "        print(trial_data.shape)\n",
    "        print(selected_esm.shape)\n",
    "        np.save(os.path.join(path,'data', subject + '_trials.npy'), trial_data.astype(np.float32))\n",
    "        selected_esm.to_csv(os.path.join(path,'data', subject + '_esm.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45224fd8-21b0-47f0-b60d-88e88079012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(data, esm,sr, windowLength=60):\n",
    "\n",
    "    numSamples=data.shape[0]\n",
    "    # Getting number and names of features\n",
    "    tremorNames, _ = tremorFeatures(data[0,:windowLength*sr,:], sr,windowLength=windowLength)\n",
    "    bradyNames, _ = bradykinesiaFeatures(data[0,:windowLength*sr,:], sr,windowLength=windowLength)\n",
    "    cols=[]\n",
    "    for s in ['L','R','C']:\n",
    "        cols.extend([c + s for c in tremorNames])\n",
    "        cols.extend([c + s for c in bradyNames])\n",
    "    cols.extend(esm.keys())\n",
    "    aligned = pd.DataFrame(columns=cols)\n",
    "    accelerometerChannel = [a + b for a in  [0,6,12] for b in range(3)]\n",
    "    for beep in np.arange(data.shape[0]):\n",
    "        t=time.time()\n",
    "        allFeat = []\n",
    "        numWindows = int(data.shape[1]/sr/windowLength)\n",
    "        buff = data[beep,:,:]\n",
    "        buff[:,accelerometerChannel] = (buff[:,accelerometerChannel].T - np.mean(buff[:,accelerometerChannel].T,axis=0)).T\n",
    "        for s,sID in enumerate([range(6),range(6,12),range(12,18)]):\n",
    "            \n",
    "            features=np.zeros((numWindows,len(tremorNames)+len(bradyNames)))\n",
    "            for i in range(0,numWindows):\n",
    "                win = i * windowLength * sr\n",
    "                _, features[i,:len(tremorNames)] = tremorFeatures(buff[win:win+windowLength*sr,sID],sr,windowLength=windowLength)\n",
    "                _, features[i,len(tremorNames):] = bradykinesiaFeatures(buff[win:win+windowLength*sr,sID],sr,windowLength=windowLength)\n",
    "            allFeat.append(features)\n",
    "        allFeat = np.concatenate(allFeat,axis=1)\n",
    "        allFeat = np.concatenate((allFeat, np.matlib.repmat(esm.iloc[beep,:],numWindows,1)),axis=1)\n",
    "        aligned = aligned.append(pd.DataFrame(allFeat,columns = cols),ignore_index=True)\n",
    "    \n",
    "    return aligned \n",
    "\n",
    "\n",
    "\n",
    "def tremorFeatures(windowData,sr,windowLength=60):\n",
    "    tremorChannel={'AccX':0,'AccY':1,'AccZ':2,'GyrX':3,'GyrY':4,'GyrZ':5} \n",
    "    if windowData.shape[0]!=sr*windowLength:\n",
    "        print(windowData.shape,sr*windowLength)\n",
    "    features=[]\n",
    "    featureNames=[]\n",
    "    for ch in tremorChannel.keys():\n",
    "        f, spec = welch(windowData[:,tremorChannel[ch]], fs=sr, nperseg=sr )\n",
    "        selected = np.logical_and(f>3.5,f<7.5)\n",
    "        spec = np.mean(np.log(spec[selected]))\n",
    "        features.append(spec)\n",
    "        featureNames.append('TremorPower' + ch)\n",
    "        \n",
    "        \n",
    "    return featureNames, features\n",
    "\n",
    "\n",
    "\n",
    "def bradykinesiaFeatures(windowData,sr,windowLength=60):\n",
    "    features=[]\n",
    "    featureNames=[]\n",
    "    accelerometerChannel={'accX':0,'accY':1,'accZ':2} \n",
    "    windowData = filter_data(windowData[:,list(accelerometerChannel.values())].T,sr,0,3,method='iir',verbose='WARNING').T\n",
    "    \n",
    "    freq = np.fft.rfftfreq(windowLength*sr, d=1./sr)\n",
    "    \n",
    "    for ch in accelerometerChannel.keys():\n",
    "        f, spec = welch(windowData[:,accelerometerChannel[ch]], fs=sr, nperseg=sr )\n",
    "        selected = np.logical_and(f>0.5,f<3.0)\n",
    "        spec = np.mean(np.log(spec[selected])) \n",
    "        features.append(spec)\n",
    "        featureNames.append('bradyPower' + ch)\n",
    "        \n",
    "        spec = np.abs(np.fft.rfft(windowData[:,accelerometerChannel[ch]]))\n",
    "        domFreq = freq[np.argmax(spec)]\n",
    "        features.append(domFreq)\n",
    "        featureNames.append('DomFreq' + ch)\n",
    "        \n",
    "        domEnergyRatio = np.max(spec) / np.sum(spec)\n",
    "        features.append(domEnergyRatio)\n",
    "        featureNames.append('DomEnergyRatio' + ch)\n",
    "        \n",
    "        rms = np.sqrt(np.mean(windowData[:,accelerometerChannel[ch]]**2))\n",
    "        features.append(rms)\n",
    "        featureNames.append('RMS' + ch)\n",
    "        \n",
    "        ampRange = np.max(windowData[:,accelerometerChannel[ch]]) - np.min(windowData[:,accelerometerChannel[ch]])\n",
    "        features.append(ampRange)\n",
    "        featureNames.append('AmpRange' + ch)\n",
    "    \n",
    "    cCMax=[]\n",
    "    cCLocs=[]\n",
    "    for i, ch1 in enumerate(accelerometerChannel.keys()):\n",
    "        for j,ch2 in enumerate(list(accelerometerChannel.keys())[i+1:]):\n",
    "            crossCorr = np.correlate(windowData[:,accelerometerChannel[ch1]],windowData[:,accelerometerChannel[ch2]],'same')\n",
    "            crossCorr = crossCorr/(np.std(windowData[:,accelerometerChannel[ch1]]) * np.std(windowData[:,accelerometerChannel[ch2]]))\n",
    "            \n",
    "            cCMax.append(np.max(crossCorr))\n",
    "            cCLocs.append(np.argmax(crossCorr))\n",
    "    features.append(np.max(cCMax))\n",
    "    featureNames.append('MaxCC')\n",
    "    features.append(cCLocs[np.argmax(cCMax)])\n",
    "    featureNames.append('MaxCCLoc')\n",
    "        \n",
    "    return featureNames, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fc35d6-2337-407c-bb75-64842e95c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "allPts = ['110001'] \n",
    "sr=100\n",
    "winL = 900 # seconds\n",
    "for pt in allPts:\n",
    "    print(pt)\n",
    "    trialData = np.load(join(path,'data', pt + '_trials.npy')).astype(np.float64)\n",
    "    esm = pd.read_csv(join(path,'data',  pt + '_esm.csv'))\n",
    "    alignedFeatures = extractFeatures(trialData,esm,sr,windowLength=winL)\n",
    "    alignedFeatures.to_csv(join(path,'data',  pt + '_features' +  str(winL)  + '.csv'),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40be305-7436-4a64-b3bd-5f0ebf884a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareWristChest(pt):\n",
    "    '''\n",
    "    Input:\n",
    "    pt = pt-code as string, e.g. '110018'\n",
    "    sensor_source = 'wrists' or 'chest', defines which movement sensors to use for prediction.\n",
    "    \n",
    "    Output:\n",
    "    png file in results-folder.\n",
    "    '''\n",
    "    esmTarget = 'sanpar_onoff'\n",
    "    \n",
    "    esmColumns = ['subjno', 'mood_well', 'mood_down', 'mood_fright', 'mood_tense', 'phy_sleepy', 'phy_tired',\n",
    "           'mood_cheerf', 'mood_relax', 'thou_concent', 'pat_hallu', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03', 'act_what', 'act_what02',\n",
    "           'act_what03', 'act_norpob', 'prob_mobility', 'prob_stillness',\n",
    "           'prob_speech', 'prob_walking', 'tremor', 'slowness',\n",
    "           'stiffness', 'tension', 'dyskinesia', 'onoff',\n",
    "           'medic', 'beep_disturb', '_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration']\n",
    "\n",
    "    drop=[ 'subjno','soc_who', 'soc_who02', 'soc_who03',  'act_what02', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03',  'act_what02',\n",
    "           'act_what03','_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration','castorID'] # keep 'act_what' in\n",
    "\n",
    "    fig,ax = plt.subplots(1,2, figsize=(12,6))\n",
    "    sns.set_context('paper')\n",
    "    titles = ['Wrist data\\n(intended use)','Chest data\\n(non-intended use)']\n",
    "    ab = ['A','B']\n",
    "    for n,sensor_source in enumerate(['wrists','chest']):\n",
    "        esmFeatures = pd.read_csv(os.path.join(path,'data',pt+'_features900.csv'),index_col=False)\n",
    "        esmFeatures = esmFeatures.drop(drop, axis=1, errors='ignore')\n",
    "        dat = esmFeatures.drop(esmColumns,axis=1,errors='ignore')\n",
    "\n",
    "        if sensor_source == 'chest':\n",
    "            feats = [c for c in dat.keys() if c[-1] == 'C'] # takes only features from chest-sensor\n",
    "        elif sensor_source == 'wrists':\n",
    "            feats = [c for c in dat.keys() if c[-1] == 'R' ]\n",
    "            feats.extend([c for c in dat.keys() if c[-1] == 'L'])# takes features from left and right wrist-sensor\n",
    "        # define x\n",
    "        dat = dat[feats]\n",
    "        x=dat.loc[~np.isnan(esmFeatures[esmTarget]),:].values\n",
    "        # define y\n",
    "        y=esmFeatures[esmTarget][~np.isnan(esmFeatures[esmTarget])].values\n",
    "        y=y==3 # 3 is ON-answer in EMA\n",
    "\n",
    "        # define classifier, cv to use, and number of cross-validation folds\n",
    "        est=LogisticRegression(solver='lbfgs')\n",
    "        folds = 5 \n",
    "        kf = KFold(n_splits=folds)\n",
    "        scores = np.zeros((y.shape[0],2))\n",
    "        aucs=[]\n",
    "        for fold, (train,test) in enumerate(kf.split(x)): \n",
    "            est.fit(x[train,:],y[train]) \n",
    "            if hasattr(est, \"predict_proba\"): \n",
    "                prob_pos = est.predict_proba(x[test,:])#[:, 0]\n",
    "            else:  \n",
    "                prob_pos = est.decision_function(x[test,:])\n",
    "            scores[test,:]=prob_pos\n",
    "            aucs.append(roc_auc_score(y[test]==1, scores[test,0]))\n",
    "        auc = roc_auc_score(y==1, scores[:,0]) \n",
    "        (fpr, tpr, treshs) = roc_curve(y==1, scores[:,0]) \n",
    "    #     print('Participant %s has overall auc %f' %(pt,auc)) \n",
    "\n",
    "        ## Plot figure\n",
    "        ax[n].plot(fpr,tpr,'o-', lw=2.5, markersize=8)\n",
    "        ax[n].plot(np.arange(0,1.1,0.1),np.arange(0,1.1,0.1), lw=1.5)\n",
    "        ax[n].set_xlabel('False Positive Rate', fontsize=18)\n",
    "        ax[n].set_ylabel('True Positive Rate',fontsize=18)\n",
    "        ax[n].set_title(titles[n],fontsize=20)\n",
    "        ax[n].set_xticks([0,0.2,0.4,0.6,0.8,1])\n",
    "        ax[n].set_yticks([0,0.2,0.4,0.6,0.8,1])\n",
    "        ax[n].set_xticklabels([0,0.2,0.4,0.6,0.8,1],fontsize=18)\n",
    "        ax[n].set_yticklabels([0,0.2,0.4,0.6,0.8,1],fontsize=18)\n",
    "        ax[n].annotate(ab[n], xy=(-.05,1.05), xycoords='axes fraction', fontsize=48)\n",
    "        sns.despine()\n",
    "        ax[n].grid()\n",
    "    plt.tight_layout(w_pad=3)\n",
    "    plt.savefig(os.path.join(path,'results','DATA_fig2.png'),dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cb9410-f636-4ccd-a6d3-f1d266c0788b",
   "metadata": {},
   "outputs": [],
   "source": [
    "compareWristChest('110001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c105af6-2cfc-4c93-9651-47ea9156ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictMedState(pt, sensor_source):\n",
    "    '''\n",
    "    Input:\n",
    "    pt = pt-code as string, e.g. '110018'\n",
    "    sensor_source = 'wrists' or 'chest', defines which movement sensors to use for prediction.\n",
    "    \n",
    "    Output:\n",
    "    png file in results-folder.\n",
    "    '''\n",
    "    esmTarget = 'sanpar_onoff'\n",
    "    \n",
    "    esmColumns = ['subjno', 'mood_well', 'mood_down', 'mood_fright', 'mood_tense', 'phy_sleepy', 'phy_tired',\n",
    "           'mood_cheerf', 'mood_relax', 'thou_concent', 'pat_hallu', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03', 'act_what', 'act_what02',\n",
    "           'act_what03', 'act_norpob', 'prob_mobility', 'prob_stillness',\n",
    "           'prob_speech', 'prob_walking', 'tremor', 'slowness',\n",
    "           'stiffness', 'tension', 'dyskinesia', 'onoff',\n",
    "           'medic', 'beep_disturb', '_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration']\n",
    "\n",
    "    drop=[ 'subjno','soc_who', 'soc_who02', 'soc_who03',  'act_what02', 'loc_where',\n",
    "           'soc_who', 'soc_who02', 'soc_who03',  'act_what02',\n",
    "           'act_what03','_datetime', '_datetime_e', 'dayno_n', 'beepno_n','duration','castorID'] # keep 'act_what' in\n",
    "\n",
    "    esmFeatures = pd.read_csv(os.path.join(path,'data',pt+'_features900.csv'),index_col=False)\n",
    "    esmFeatures = esmFeatures.drop(drop, axis=1, errors='ignore')\n",
    "    dat = esmFeatures.drop(esmColumns,axis=1,errors='ignore')\n",
    "    ## select defined sensor-data\n",
    "    if sensor_source == 'chest':\n",
    "        feats = [c for c in dat.keys() if c[-1] == 'C'] # takes only features from chest-sensor\n",
    "    elif sensor_source == 'wrists':\n",
    "        feats = [c for c in dat.keys() if c[-1] == 'R' ]\n",
    "        feats.extend([c for c in dat.keys() if c[-1] == 'L'])# takes features from left and right wrist-sensor\n",
    "    # define x\n",
    "    dat = dat[feats]\n",
    "    x=dat.loc[~np.isnan(esmFeatures[esmTarget]),:].values\n",
    "    # define y\n",
    "    y=esmFeatures[esmTarget][~np.isnan(esmFeatures[esmTarget])].values\n",
    "    y=y==3 # 3 is ON-answer in EMA\n",
    "\n",
    "    # define classifier, cv to use, and number of cross-validation folds\n",
    "    est=LogisticRegression(solver='lbfgs')\n",
    "    folds = 5 \n",
    "    kf = KFold(n_splits=folds)\n",
    "    scores = np.zeros((y.shape[0],2))\n",
    "    aucs=[]\n",
    "    for fold, (train,test) in enumerate(kf.split(x)): \n",
    "        est.fit(x[train,:],y[train]) \n",
    "        if hasattr(est, \"predict_proba\"): \n",
    "            prob_pos = est.predict_proba(x[test,:])#[:, 0]\n",
    "        else:  \n",
    "            prob_pos = est.decision_function(x[test,:])\n",
    "        scores[test,:]=prob_pos\n",
    "        aucs.append(roc_auc_score(y[test]==1, scores[test,0]))\n",
    "    auc = roc_auc_score(y==1, scores[:,0]) \n",
    "    (fpr, tpr, treshs) = roc_curve(y==1, scores[:,0]) \n",
    "#     print('Participant %s has overall auc %f' %(pt,auc)) \n",
    "\n",
    "    ## Plot figure\n",
    "    sns.set_context('paper')\n",
    "    fig, ax= plt.subplots(figsize=(6,6))\n",
    "\n",
    "    ax.plot(fpr,tpr,'o-', lw=2.5, markersize=8)\n",
    "    ax.plot(np.arange(0,1.1,0.1),np.arange(0,1.1,0.1), lw=1.5)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=18)\n",
    "    ax.set_ylabel('True Positive Rate',fontsize=18)\n",
    "#     ax.set_title('%s: Medication state detection\\n for %s sensor, AUC = %.2f' % (pt,sensor_source,auc),\n",
    "#                 fontsize=20)\n",
    "    plt.xticks(fontsize=14)\n",
    "    plt.yticks(fontsize=14)\n",
    "\n",
    "    sns.despine()\n",
    "    plt.grid()\n",
    "    plt.tight_layout()\n",
    "#     plt.savefig(os.path.join(path,'results','%s_%s_roc.png' %(pt,sensor_source)),dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8c1a4c-b3a6-444f-998b-b51f717fd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictMedState(pt='110018', sensor_source='wrists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1b785-d74b-4529-98bf-79eb8847458b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_data.shape\n",
    "# 7 trials\n",
    "# each trial is 900 seconds with sampling rate of 1000 samples per second = 90,000\n",
    "# in each trial, there are 18 different datapoints per sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f1a497-83a0-4083-9651-301fd8075ccf",
   "metadata": {},
   "source": [
    "# Data Visualization and Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553325b-b014-416a-b15a-5d5e6e0cb71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "!pip install jupyter-dash\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40df59b1-fe81-4a79-8ac4-0f337777b390",
   "metadata": {},
   "source": [
    "### Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de87bb56-d3d2-419d-b566-c06b6257c03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build App\n",
    "df = px.data.tips()\n",
    "app = JupyterDash(__name__)\n",
    "app.layout = html.Div([\n",
    "    html.H1(\"JupyterDash Demo\"),\n",
    "    dcc.Graph(id='graph'),\n",
    "    html.Label([\n",
    "        \"colorscale\",\n",
    "        dcc.Dropdown(\n",
    "            id='colorscale-dropdown', clearable=False,\n",
    "            value='plasma', options=[\n",
    "                {'label': c, 'value': c}\n",
    "                for c in px.colors.named_colorscales()\n",
    "            ])\n",
    "    ]),\n",
    "])# Define callback to update graph\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input(\"colorscale-dropdown\", \"value\")]\n",
    ")\n",
    "def update_figure(colorscale):\n",
    "    return px.scatter(\n",
    "        df, x=\"total_bill\", y=\"tip\", color=\"size\",\n",
    "        color_continuous_scale=colorscale,\n",
    "        render_mode=\"webgl\", title=\"Tips\"\n",
    "    )# Run app and display result inline in the notebook\n",
    "app.run_server(mode='external')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4e17ec-1dba-402b-92bb-beb59abb8303",
   "metadata": {},
   "source": [
    "### Test Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2230217-5391-4612-bb12-95355bede4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = trial_data[0,:,0]\n",
    "test1 = trial_data[0,:,1]\n",
    "test2 = trial_data[0,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fe0e12-339f-4754-a6dc-e10398c3057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "px.line(trial_data[0,:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21d5d4-9c50-41e8-a807-7e5ff66772f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(x=test, y=test1, z=test2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8001e4-9773-4706-ba6f-f695b1fd4604",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[go.Surface(z=test2, x=test, y=test1)])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c44f112-25c4-4a3b-b793-352eeebc4a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_data = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/api_docs/mt_bruno_elevation.csv')\n",
    "z = z_data.values\n",
    "z.shape\n",
    "sh_0, sh_1 = z.shape\n",
    "x, y = np.linspace(0, 1, sh_0), np.linspace(0, 1, sh_1)\n",
    "fig = go.Figure(data=[go.Surface(z=z, x=x, y=y)])\n",
    "fig.update_layout(title='Mt Bruno Elevation', autosize=False,\n",
    "                  width=500, height=500,\n",
    "                  margin=dict(l=65, r=50, b=65, t=90))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a6fcf-80ec-47b0-bcb0-9f95320d4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import griddata\n",
    "xi = np.linspace(min(test), max(test), num=200)\n",
    "yi = np.linspace(min(test1), max(test1), num=200)\n",
    "\n",
    "x_grid, y_grid = np.meshgrid(xi,yi)\n",
    "\n",
    "#Grid data\n",
    "z_grid = griddata((test, test1),test2,(x_grid,y_grid),method='cubic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43192ba7-131c-45e3-b8e3-df77f33137c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(go.Surface(x=x_grid,y=y_grid,z=z_grid,\n",
    "                       colorscale='viridis'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78c7725-18d6-48f1-85f2-70d00aed5b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
